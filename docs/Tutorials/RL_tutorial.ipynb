{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "503d3bae",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/petzschnerlab/avoid_learning_rl_models/blob/main/docs/Tutorials/RL_tutorial.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4520c3d",
   "metadata": {},
   "source": [
    "\n",
    "# RL Modelling Tutorial\n",
    "\n",
    "Welcome to the avoidance learning reinforcement learning models repo. This repo was built for the PEAC lab to computationally model empirical data from the various avoidance learning tasks. This repo has the ability to fit RL models to empirical data and to validate these models through parameters and model recovery methods.  \n",
    "\n",
    "*Note that this tutorial is designed to run in Google Colab and not from the repo itself (since it clones the repo)*\n",
    "\n",
    "<b>Supported models</b><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;QLearning, ActorCritic<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Relative, Advantage<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;Hybrid2012, Hybrid2021<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;StandardHybrid2012, StandardHybrid2021<br><br>\n",
    "\n",
    "<b>Standard models </b><br>\n",
    "Standard models as described in each reference, which introduces the model, with the addition of counterfactual learning rates.<br>\n",
    "Hybrid models have alternatives versions without counterfactual learning rates: StandardHybrid2012, StandardHybrid2021\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>QLearning</b>: Standard Q-Learning Model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>ActorCritic</b>: Standard Actor-Critic Model<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>Relative</b>: Standard Relative Model (Palminteri et al., 2015)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>Advantage</b>: Simplified Relative Model (Williams et al., 2025)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>Hybrid2012+bias</b>: Hybrid 2012 Model (Gold et al., 2012)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>Hybrid2021+bias+decay</b>: Hybrid 2021 Model (Geana et al., 2021)<br><br>\n",
    "\n",
    "<b>Optional Parameters</b><br>\n",
    "You can add optional parameters to models by adding them to the model name using a + sign<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>+bias</b>: Adds a valence bias to the model (e.g. Hybrid2012+bias), only usable with Hybrid models<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>+novel</b>: Adds a free parameter for the novel stimulus (e.g. QLearning+novel), useable with all models<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;<b>+decay</b>: Adds a decay parameter to the model (e.g. QLearning+decay), useable with all models\n",
    "\n",
    "## Project Pipeline\n",
    "This repo is one part of a project pipeline, which requires the coordination of multiple repos. Projects begin with a <b>task repo</b>, which is used to collect behavioural data from participants either locally or on Prolific. The collected data must then be pushed through a <b>data extraction repo</b> to prepare CSV files for analysis. These CSV files are used in <b>the analysis repo</b>, which creates a PDF report (`AL/reports`), ending the project pipeline. \n",
    "\n",
    "Optionally, you can run computational reinforcement learning models using the <b>modelling repo (this repo)</b>, and the results can be added to the report. This is a bit clunky because it requires a bit of back-and-forth between the analysis repo and this modelling repo. Specifically, the analysis repo must be run (with `load_models=False`) in order to create two CSV files that this repo needs (`AL/data/pain_learning_processed.csv` and `AL/data/pain_transfer_processed.csv`). These files can then be manually moved into this repo's data directory (`RL/data`). This repo can then be used to model the data, which will result in a newly constructed directory called `modelling` (`RL/modelling`). This folder can then be manually moved to the analysis repo as `AL/modelling`. Then you can re-run the analysis repo (with `load_models=True`) and the modelling results will be included in the PDF report. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4702b22f",
   "metadata": {},
   "source": [
    "## Cloning the Repo\n",
    "\n",
    "We will begin by cloning the repo, installing dependencies, and then adding this repo as a system path. Adding the repo in the system path is only necessary for this tutorial. We also change directory to the repo. When using locally, you can create your script in the `AL` source folder, in the same manner as `AL_main.py` (`avoid_learning_analysis/AL/AL_main.py`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c10e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# We will now clone the repo, pull any updates, and install dependencies\n",
    "!git clone https://github.com/petzschnerlab/avoid_learning_rl_models.git\n",
    "%cd avoid_learning_rl_models/\n",
    "!git pull\n",
    "!pip install .\n",
    "\n",
    "#Only necessary for Google Colab\n",
    "sys.path.insert(0, os.path.abspath(\"/content/avoid_learning_rl_models/RL\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2edb154",
   "metadata": {},
   "source": [
    "## The Pipeline\n",
    "\n",
    "Next, we will import the Pipeline class. This class is the entry point to this repo. It will take in all of your parameters and run the corresponding analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ead85be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f88e700",
   "metadata": {},
   "source": [
    "### The Help Function\n",
    "\n",
    "The pipeline has a help function that will outline some information about the repo and then describe all of the parameters. These details are also available in the documentation. We will use the `help=True` parameters in order to see this help function below. \n",
    "\n",
    "This parameter can be passed to the Pipeline during initiatialization:\n",
    "```\n",
    "pipeline = Pipeline(help=True)\n",
    "```\n",
    "\n",
    "or to the pipeline run method of the class:\n",
    "```\n",
    "pipeline = Pipeline()\n",
    "pipeline.run(help=True)\n",
    "```\n",
    "\n",
    "The help information gets truncated in Jupyter notebooks, but you can view the whole output by clicking `scrollable element`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53acdf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(help=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cc529c0",
   "metadata": {},
   "source": [
    "## Fitting Models\n",
    "\n",
    "There are two modes in this repo, `fit` and `validation`. In FIT mode, models are fitted to empirical data. In VALIDATION mode, parameter recovery or model recovery is performed, depending on the recovery parameter. We will begin by fitting several RL models to our empirical data. \n",
    "\n",
    "We will define a typical set of parameters for this package below, see the help information above to understand what each parameters does. Note that in this example, we extract our priors using the fixed_priors function. Note that here we will be using learning and transfer filenames `tutorial_learning_data.csv` and `tutorial_transfer_data.csv`, respectively, but the default filenames exported by the analysis repo are `pain_learning_processed.csv` and `pain_transfer_processed.csv`. Finally, it is highly recommended to use multiprocessing if possible as we are doing here (e.g., `multiprocessing=True`). Especially when you have a lot of participants, are running many models, and including many runs, this will take a very long time if you are not using multiprocessing. It will still take a good amount of time when using multiprocessing.\n",
    "\n",
    "A final note is that we are setting a seed when initializing the pipeline to ensure replicability because this repo does use randomization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10943fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.priors import fixed_priors\n",
    "\n",
    "models = ['QLearning+novel',    #Standard + novel\n",
    "          'ActorCritic+novel',  #Standard + novel\n",
    "          'Advantage+novel',    #Standard + novel\n",
    "]\n",
    "    \n",
    "fixed = fixed_priors(models)    \n",
    "fit_params = {'mode':                       'fit',\n",
    "              'learning_filename':          'RL/data/tutorial_learning_data.csv',\n",
    "              'transfer_filename':          'RL/data/tutorial_transfer_data.csv',\n",
    "              'models':                     models,\n",
    "              'random_params':              'normal',\n",
    "              'fixed':                      fixed,\n",
    "              'multiprocessing':            True,\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(seed=1251)\n",
    "pipeline.run(**fit_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb01b7d",
   "metadata": {},
   "source": [
    "### Fitting Results\n",
    "\n",
    "Now that we have finished fitting the models to our data, we can look at a couple of plots to see the results. After the fitting procedure, a new folder is created `RL/modelling`. This folder contains all important results (statistics, plots, etc.). The intent of this folder is to move it to the analysis repo and that way you can add your modelling results to your PDF report. For this tutorial we will look at a couple of plots to see our results.\n",
    "\n",
    "Let's begin by viewing the BIC plot, which will tell us which model fit the data the best. Remember, the lower this value the better the data fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7087c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename='RL/modelling/BIC-model-comparisons.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14b2bf8",
   "metadata": {},
   "source": [
    "We can also view the fits from the BIC table, which will also show us the best fits for each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e0ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "BIC_fits = pd.read_csv('RL/modelling/group_BIC.csv')\n",
    "BIC_fits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c4a9ca",
   "metadata": {},
   "source": [
    "The fitting procedure also runs model simulations using the fitted parameters of each participant. We can also view these simulation results. We will view the best models simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082007d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = BIC_fits['best_model'].values[-1]\n",
    "print(best_model)\n",
    "\n",
    "display(Image(filename=f'RL/modelling/model_behaviours/{best_model}_model_behaviours.png', width=800, height=600))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOMA_AL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
